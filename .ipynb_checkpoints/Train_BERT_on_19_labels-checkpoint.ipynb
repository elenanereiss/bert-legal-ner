{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a716ed8f",
   "metadata": {},
   "source": [
    "# Training with 19 fine-grained labels\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "Download the [German LER Dataset](https://github.com/elenanereiss/Legal-Entity-Recognition) splits (train, dev, test) from GitHub and save it in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47400dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_train.conll -P data\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_dev.conll -P data\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_test.conll -P data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad1e99",
   "metadata": {},
   "source": [
    "We can define some variables that we need for further pre-processing steps and training the model.\n",
    "You can find more models for training on ðŸ¤— [huggingface](https://huggingface.co/models?language=de&pipeline_tag=fill-mask&sort=downloads), for example:\n",
    "- **BERT multilingual** (`bert-base-multilingual-cased`, `bert-base-multilingual-uncased`)\n",
    "- **BERT German** (`bert-base-german-cased`, `dbmdz/bert-base-german-uncased`, ...)\n",
    "- **DistilBERT** (`distilbert-base-german-cased`, `distilbert-base-multilingual-cased`)\n",
    "- **XLM-RoBERTa** (`xlm-roberta-base`, `xlm-roberta-large`, `facebook/xlm-roberta-xl`, ...)\n",
    "- **ELECTRA** (`stefan-it/electra-base-gc4-64k-200000-cased-generator`, ...)\n",
    "- **DeBERTa** (`microsoft/mdeberta-v3-base`)\n",
    "- ...\n",
    "\n",
    "We use [bert-base-german-cased](https://huggingface.co/bert-base-german-cased) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DATA_DIR=data\n",
    "export MODEL_DIR=models\n",
    "\n",
    "export MAX_LENGTH=512\n",
    "export BERT_MODEL=bert-base-german-cased\n",
    "\n",
    "export TRAIN=$DATA_DIR/ler_train.conll\n",
    "export DEV=$DATA_DIR/ler_dev.conll\n",
    "export TEST=$DATA_DIR/ler_test.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864b8ff",
   "metadata": {},
   "source": [
    "Court decisions consists of long sentences that need to be edited. The `preprocess.py` script splits longer sentences into smaller ones (once the max. subtoken length is reached).\n",
    "Run the pre-processing script on train, dev and test datasets splits. Note that the script `run_ner.py` takes the following files for training and evaluation: `train.txt`, `dev.txt`, `test.txt`. Then we collect all the labels from the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 src/preprocess.py $TRAIN $BERT_MODEL $MAX_LENGTH > $DATA_DIR/train.txt\n",
    "python3 src/preprocess.py $DEV $BERT_MODEL $MAX_LENGTH > $DATA_DIR/dev.txt\n",
    "python3 src/preprocess.py $TEST $BERT_MODEL $MAX_LENGTH > $DATA_DIR/test.txt\n",
    "cat $DATA_DIR/ler_train.conll $DATA_DIR/ler_dev.conll $DATA_DIR/ler_test.conll | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq >  $DATA_DIR/labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd6450",
   "metadata": {},
   "source": [
    "# Training\n",
    "## Training with Pytorch\n",
    "\n",
    "To see what arguments can be set, run `python3 run_ner.py --help`.\n",
    "\n",
    "BERT is trained and evaluated on dev and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad25ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_ner.py --data_dir $DATA_DIR \\\n",
    "    --labels $DATA_DIR/labels.txt \\\n",
    "    --task_type NER \\\n",
    "    --model_name_or_path $BERT_MODEL \\\n",
    "    --output_dir $MODEL_DIR/$BERT_MODEL-$LABEL_TYPE-$MAX_LENGTH \\\n",
    "    --max_seq_length $MAX_LENGTH \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_gpu_train_batch_size 12 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --save_steps 7500 \\\n",
    "    --seed 1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794455c",
   "metadata": {},
   "source": [
    "Results on the dev set:\n",
    "\n",
    "```bash\n",
    "10/30/2022 17:42:03 - INFO - __main__ - ***** Eval results *****\n",
    "10/30/2022 17:42:03 - INFO - __main__ -   eval_precision = 0.9212203128016991\n",
    "10/30/2022 17:42:03 - INFO - __main__ -   eval_recall = 0.9458762886597938\n",
    "10/30/2022 17:42:03 - INFO - __main__ -   eval_f1 = 0.9333855032769246\n",
    "```\n",
    "\n",
    "Results on the test set:\n",
    "\n",
    "```bash\n",
    "[INFO|trainer.py:2891] 2022-10-30 17:42:14,836 >> ***** Running Prediction *****\n",
    "10/30/2022 17:45:18 - INFO - __main__ -   test_precision = 0.9449558173784978\n",
    "10/30/2022 17:45:18 - INFO - __main__ -   test_recall = 0.9644870349492672\n",
    "10/30/2022 17:45:18 - INFO - __main__ -   test_f1 = 0.9546215361725869\n",
    "```\n",
    "\n",
    "## Training with Tensorflow\n",
    "\n",
    "To see what arguments can be set, also run `python3 run_tf_ner.py --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb573744",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_tf_ner.py --data_dir $DATA_DIR \\\n",
    "    --labels $DATA_DIR/labels.txt \\\n",
    "    --task_type NER \\\n",
    "    --model_name_or_path $BERT_MODEL \\\n",
    "    --output_dir $MODEL_DIR/$BERT_MODEL-$LABEL_TYPE-$MAX_LENGTH \\\n",
    "    --max_seq_length $MAX_LENGTH \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_gpu_train_batch_size 12 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --save_steps 7500 \\\n",
    "    --seed 1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ef77c",
   "metadata": {},
   "source": [
    "Results on the dev set:\n",
    "\n",
    "```\n",
    "[INFO|trainer_tf.py:320] 2022-11-02 09:04:17,682 >> ***** Running Prediction *****\n",
    "11/02/2022 09:05:46 - INFO - __main__ -\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          AN       0.75      0.50      0.60        12\n",
    "         EUN       0.92      0.93      0.92       116\n",
    "         GRT       0.95      0.99      0.97       331\n",
    "          GS       0.98      0.98      0.98      1720\n",
    "         INN       0.84      0.91      0.88       199\n",
    "          LD       0.95      0.95      0.95       109\n",
    "         LDS       0.82      0.43      0.56        21\n",
    "         LIT       0.88      0.92      0.90       231\n",
    "         MRK       0.50      0.70      0.58        23\n",
    "         ORG       0.64      0.71      0.67       103\n",
    "         PER       0.86      0.93      0.90       186\n",
    "          RR       0.97      0.98      0.97       144\n",
    "          RS       0.94      0.95      0.94      1126\n",
    "          ST       0.91      0.88      0.89        58\n",
    "         STR       0.29      0.29      0.29         7\n",
    "          UN       0.81      0.85      0.83       143\n",
    "          VO       0.76      0.95      0.84        37\n",
    "          VS       0.62      0.80      0.70        56\n",
    "          VT       0.87      0.92      0.90       275\n",
    "\n",
    "   micro avg       0.92      0.94      0.93      4897\n",
    "   macro avg       0.80      0.82      0.80      4897\n",
    "weighted avg       0.92      0.94      0.93      4897\n",
    "```\n",
    "\n",
    "Results on the test set:\n",
    "\n",
    "```\n",
    "[INFO|trainer_tf.py:320] 2022-11-02 09:11:42,672 >> ***** Running Prediction *****\n",
    "11/02/2022 09:19:33 - INFO - __main__ -\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          AN       1.00      0.89      0.94         9\n",
    "         EUN       0.90      0.97      0.93       150\n",
    "         GRT       0.98      0.98      0.98       321\n",
    "          GS       0.98      0.99      0.98      1818\n",
    "         INN       0.90      0.95      0.92       222\n",
    "          LD       0.97      0.92      0.94       149\n",
    "         LDS       0.91      0.45      0.61        22\n",
    "         LIT       0.92      0.96      0.94       314\n",
    "         MRK       0.78      0.88      0.82        32\n",
    "         ORG       0.82      0.88      0.85       113\n",
    "         PER       0.92      0.88      0.90       173\n",
    "          RR       0.95      0.99      0.97       142\n",
    "          RS       0.97      0.98      0.97      1245\n",
    "          ST       0.79      0.86      0.82        64\n",
    "         STR       0.75      0.80      0.77        15\n",
    "          UN       0.90      0.95      0.93       108\n",
    "          VO       0.80      0.83      0.81        71\n",
    "          VS       0.73      0.84      0.78        64\n",
    "          VT       0.93      0.97      0.95       290\n",
    "\n",
    "   micro avg       0.94      0.96      0.95      5322\n",
    "   macro avg       0.89      0.89      0.89      5322\n",
    "weighted avg       0.95      0.96      0.95      5322\n",
    "```\n",
    "\n",
    "# Evaluation\n",
    "The model (e.g. `bert-base-german-cased`, saved in the folder `models/bert-base-german-cased-fine-512`) can be easily evaluated (Pytorch or Tensorflow) with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_ner.py --data_dir data   --task_type NER   --model_name_or_path models/bert-base-german-cased-fine-512   --output_dir models/bert-base-german-cased-fine-512   --do_eval   --do_predict --labels data/labels.txt   --per_device_eval_batch 16   --max_seq_length 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111be82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_tf_ner.py --data_dir data   --task_type NER   --model_name_or_path models/bert-base-german-cased-fine-512   --output_dir models/bert-base-german-cased-fine-512   --do_eval   --do_predict --labels data/labels.txt   --per_device_eval_batch 16   --max_seq_length 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
