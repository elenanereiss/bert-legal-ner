{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e4b3bf",
   "metadata": {},
   "source": [
    "# Training with 7 coarse-grained labels\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "If the [German LER Dataset](https://github.com/elenanereiss/Legal-Entity-Recognition) has not already been downloaded, download the dataset from GitHub and save it in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e72991",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_train.conll -P data\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_dev.conll -P data\n",
    "wget https://raw.githubusercontent.com/elenanereiss/Legal-Entity-Recognition/master/data/ler_test.conll -P data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6bcf2",
   "metadata": {},
   "source": [
    "We can define some variables that we need for further pre-processing steps and training the model.\n",
    "You can find more models for training on ðŸ¤— [huggingface](https://huggingface.co/models?language=de&pipeline_tag=fill-mask&sort=downloads), for example:\n",
    "- **BERT multilingual** (`bert-base-multilingual-cased`, `bert-base-multilingual-uncased`)\n",
    "- **BERT German** (`bert-base-german-cased`, `dbmdz/bert-base-german-uncased`, ...)\n",
    "- **DistilBERT** (`distilbert-base-german-cased`, `distilbert-base-multilingual-cased`)\n",
    "- **XLM-RoBERTa** (`xlm-roberta-base`, `xlm-roberta-large`, `facebook/xlm-roberta-xl`, ...)\n",
    "- **ELECTRA** (`stefan-it/electra-base-gc4-64k-200000-cased-generator`, ...)\n",
    "- **DeBERTa** (`microsoft/mdeberta-v3-base`)\n",
    "- ...\n",
    "\n",
    "We use [bert-base-german-cased](https://huggingface.co/bert-base-german-cased) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DATA_DIR=data\n",
    "export MODEL_DIR=models\n",
    "\n",
    "export MAX_LENGTH=512\n",
    "export BERT_MODEL=bert-base-german-cased\n",
    "\n",
    "export TRAIN=$DATA_DIR/ler_train.conll\n",
    "export DEV=$DATA_DIR/ler_dev.conll\n",
    "export TEST=$DATA_DIR/ler_test.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc8b49",
   "metadata": {},
   "source": [
    "First generate coarse-grained labels from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 src/generate_coarse_labels.py $DATA_DIR/ler_train.conll $DATA_DIR/lerc_train.conll\n",
    "python3 src/generate_coarse_labels.py $DATA_DIR/ler_dev.conll $DATA_DIR/lerc_dev.conll\n",
    "python3 src/generate_coarse_labels.py $DATA_DIR/ler_test.conll $DATA_DIR/lerc_test.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de125f0",
   "metadata": {},
   "source": [
    "Then edit the splits. The `preprocess.py` script splits longer sentences into smaller ones (once the max. subtoken length is reached). Run the pre-processing script on train, dev and test datasets splits. Note that the script `run_ner.py` takes the following files for training and evaluation: `train.txt`, `dev.txt`, `test.txt`. Then we collect all the labels from the splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda385ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 src/preprocess.py $TRAIN $BERT_MODEL $MAX_LENGTH > $DATA_DIR/train.txt\n",
    "python3 src/preprocess.py $DEV $BERT_MODEL $MAX_LENGTH > $DATA_DIR/dev.txt\n",
    "python3 src/preprocess.py $TEST $BERT_MODEL $MAX_LENGTH > $DATA_DIR/test.txt\n",
    "cat $DATA_DIR/lerc_train.conll $DATA_DIR/lerc_dev.conll $DATA_DIR/lerc_test.conll | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq >  $DATA_DIR/labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aa6e9",
   "metadata": {},
   "source": [
    "## Training with Pytorch\n",
    "\n",
    "To see what arguments can be set, run `python3 run_ner.py --help`.\n",
    "\n",
    "BERT is trained and evaluated on dev and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_ner.py --data_dir $DATA_DIR \\\n",
    "    --labels $DATA_DIR/labels.txt \\\n",
    "    --task_type NER \\\n",
    "    --model_name_or_path $BERT_MODEL \\\n",
    "    --output_dir $MODEL_DIR/$BERT_MODEL-$LABEL_TYPE-$MAX_LENGTH \\\n",
    "    --max_seq_length $MAX_LENGTH \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_gpu_train_batch_size 12 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --save_steps 7500 \\\n",
    "    --seed 1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c80b5",
   "metadata": {},
   "source": [
    "Results on the dev set:\n",
    "\n",
    "```bash\n",
    "11/03/2022 16:30:04 - INFO - __main__ - ***** Eval results *****\n",
    "11/03/2022 16:30:04 - INFO - __main__ -   eval_precision = 0.9312814556716996\n",
    "11/03/2022 16:30:04 - INFO - __main__ -   eval_recall = 0.953806502775575\n",
    "11/03/2022 16:30:04 - INFO - __main__ -   eval_f1 = 0.9424094025465231\n",
    "```\n",
    "\n",
    "Results on the test set:\n",
    "\n",
    "```bash\n",
    "[INFO|trainer.py:2753] 2022-11-03 16:30:05,402 >> ***** Running Prediction *****\n",
    "11/03/2022 16:37:15 - INFO - __main__ -   test_precision = 0.9537241887905604\n",
    "11/03/2022 16:37:15 - INFO - __main__ -   test_recall = 0.9720030063885757\n",
    "11/03/2022 16:37:15 - INFO - __main__ -   test_f1 = 0.9627768471989577\n",
    "```\n",
    "\n",
    "## Training with Tensorflow\n",
    "\n",
    "To see what arguments can be set, also run `python3 run_tf_ner.py --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_tf_ner.py --data_dir $DATA_DIR \\\n",
    "    --labels $DATA_DIR/labels.txt \\\n",
    "    --task_type NER \\\n",
    "    --model_name_or_path $BERT_MODEL \\\n",
    "    --output_dir $MODEL_DIR/$BERT_MODEL-$LABEL_TYPE-$MAX_LENGTH \\\n",
    "    --max_seq_length $MAX_LENGTH \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_gpu_train_batch_size 12 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --save_steps 7500 \\\n",
    "    --seed 1 \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873bc02e",
   "metadata": {},
   "source": [
    "# Results on the dev set:\n",
    "\n",
    "```\n",
    "11/03/2022 16:46:16 - INFO - __main__ - ***Classification report for dev split***\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         LIT       0.90      0.94      0.92       264\n",
    "         LOC       0.92      0.91      0.91       195\n",
    "         NRM       0.97      0.98      0.98      1887\n",
    "         ORG       0.87      0.91      0.89       807\n",
    "         PER       0.95      0.96      0.95       348\n",
    "         REG       0.83      0.92      0.87       334\n",
    "          RS       0.94      0.96      0.95      1209\n",
    "\n",
    "   micro avg       0.93      0.95      0.94      5044\n",
    "   macro avg       0.91      0.94      0.93      5044\n",
    "weighted avg       0.93      0.95      0.94      5044\n",
    "```\n",
    "\n",
    "Results on the test set:\n",
    "\n",
    "```\n",
    "11/03/2022 16:58:31 - INFO - __main__ - ***Classification report for test split***\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         LIT       0.93      0.97      0.95       314\n",
    "         LOC       0.95      0.95      0.95       250\n",
    "         NRM       0.97      0.98      0.98      2039\n",
    "         ORG       0.93      0.96      0.95       796\n",
    "         PER       0.97      0.95      0.96       324\n",
    "         REG       0.87      0.95      0.91       354\n",
    "          RS       0.96      0.98      0.97      1245\n",
    "\n",
    "   micro avg       0.95      0.97      0.96      5322\n",
    "   macro avg       0.94      0.96      0.95      5322\n",
    "weighted avg       0.95      0.97      0.96      5322\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./fine_run.sh bert-base-german-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b246e",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "The model (e.g. `bert-base-german-cased`, saved in the folder `models/bert-base-german-cased-coarse-512`) can be easily evaluated (Pytorch or Tensorflow) with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_ner.py --data_dir data   --task_type NER   --model_name_or_path models/bert-base-german-cased-coarse-512   --output_dir models/bert-base-german-cased-coarse-512   --do_eval   --do_predict --labels data/labels.txt   --per_device_eval_batch 16   --max_seq_length 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d118a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 run_tf_ner.py --data_dir data   --task_type NER   --model_name_or_path models/bert-base-german-cased-coarse-512   --output_dir models/bert-base-german-cased-coarse-512   --do_eval   --do_predict --labels data/labels.txt   --per_device_eval_batch 16   --max_seq_length 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
